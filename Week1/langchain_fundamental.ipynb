{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu-Mac7USyVR"
      },
      "source": [
        "## Introduction to LangChain:\n",
        "LangChain is a framework for developing applications powered by language models.According to their team the most powerful and differentiated applications will not only call out to a language model via an API, but will also:\n",
        "\n",
        "- Be data-aware: connect a language model to other sources of data\n",
        "\n",
        "- Be agentic: allow a language model to interact with its environment\n",
        "\n",
        "**Links:**\n",
        "\n",
        "LangChain Docs: https://python.langchain.com/en/latest/index.html\n",
        "\n",
        "Github: https://github.com/hwchase17/langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7unYX0CyT10y"
      },
      "source": [
        "### Topics to be covered:\n",
        "- Installation\n",
        "- Available LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents & Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bPvM6LcUJ0n"
      },
      "source": [
        "### Installation\n",
        "\n",
        "LangChain is available on PyPi, so to it is easily installable with:\n",
        "\n",
        "(ref: https://tinyurl.com/3fsppvxn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG_0ANq2Srpo",
        "outputId": "067e32db-3d4b-4cca-84ad-1db2b7dfde6e"
      },
      "outputs": [],
      "source": [
        "# %pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lrcJI-PVBJC"
      },
      "source": [
        "#### Available LLMs\n",
        "\n",
        "Has integration with several different LLMs, list is here: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNwVhctZVVGZ"
      },
      "source": [
        "***OpenAI Integration***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80stER3EVUb-",
        "outputId": "ee3b315d-05e0-48c2-90b5-3701ef151c9d"
      },
      "outputs": [],
      "source": [
        "# %pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IGBf1nQ5Urpb"
      },
      "outputs": [],
      "source": [
        "# set your openai API key\n",
        "import os\n",
        "# insert API_KEY here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmxUhe4JV2kN",
        "outputId": "8dac2fd7-2d3e-490f-9d70-a9d1e91d97fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The color of the sky appears to be blue because of a phenomenon called Rayleigh scattering. This occurs when sunlight enters the Earth's atmosphere and interacts with molecules in the air, such as nitrogen and oxygen. These molecules are much smaller than the wavelength of visible light, causing them to scatter the shorter blue wavelengths more than the longer red wavelengths. As a result, the blue light becomes more dominant in the scattered light, giving the sky its blue appearance. Additionally, the Earth's atmosphere also contains particles and pollutants, which can further contribute to the blue color of the sky. \n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n",
        "prompt = \"Why the color of the sky is blue?\"\n",
        "print(llm(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EDBW4gDWT9r"
      },
      "source": [
        "***Huggingface Hub integration***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1ToEiH2tWLT-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (0.21.3)\n",
            "Requirement already satisfied: filelock in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (2024.2.0)\n",
            "Requirement already satisfied: requests in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: colorama in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface_hub) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface_hub) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AWRMqB8mWcyt"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"HUGGINGFACEHUB_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6jn_e6nPW3PV"
      },
      "outputs": [],
      "source": [
        "# from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bjL5bGZ7W6Ns"
      },
      "outputs": [],
      "source": [
        "# # https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html\n",
        "# llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0.9, \"max_length\":64})\n",
        "# prompt = \"Why gravity is lower on moon compared to earth?\"\n",
        "# print(llm(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqhtVUIyXss3"
      },
      "source": [
        "### Prompt Templates\n",
        "\n",
        "A prompt template refers to a reproducible way to generate a prompt. It contains a text string (“the template”), that can take in a set of parameters from the end user and generate a prompt.\n",
        "\n",
        "The prompt template may contain:\n",
        "\n",
        "- instructions to the language model,\n",
        "\n",
        "- a set of few shot examples to help the language model generate a better response,\n",
        "\n",
        "- a question to the language model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WEAqWjZIXC7N"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"Write a {adjective} poem about {subject}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YxNT28u3Ym4c"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"adjective\", \"subject\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kQCklrQjZvHM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Write a sad poem about ducks'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.format(adjective='sad', subject='ducks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PaGdbsxaZ5O6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n\\nIn the quiet of the pond,\\nA flock of ducks once roamed,\\nTheir feathers glinting in the sun,\\nTheir quacks a joyful tone.\\n\\nBut now the waters lie still,\\nNo flutter of wings in sight,\\nThe sky has lost its cheerful hue,\\nThe sun no longer shines bright.\\n\\nFor in a world of turmoil,\\nThe ducks were forced to flee,\\nTheir home destroyed by progress,\\nTheir future, a mystery.\\n\\nThey once had friends and family,\\nBut now they're all alone,\\nThe pond that was their sanctuary,\\nIs now a place unknown.\\n\\nAnd as the seasons change,\\nThey feel the chill in the air,\\nTheir once strong bodies now weak,\\nTheir hearts filled with despair.\\n\\nThey long for the days gone by,\\nWhere the pond was full of life,\\nWhere their wings could soar freely,\\nAnd bring them endless delight.\\n\\nBut now they're just a memory,\\nA symbol of what once was,\\nA reminder of how quickly,\\nBeauty can turn to loss.\\n\\nSo let us spare a thought,\\nFor the ducks that used to roam,\\nFor their sadness and their pain,\\nIn this world they no longer call home. \""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(prompt.format(adjective='sad', subject='ducks'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KNnkR7bU34MX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "In a pond so still and blue\n",
            "Lived a family of ducks, so happy and true\n",
            "They swam and played, with not a care\n",
            "But little did they know, of the sadness they'd bear\n",
            "\n",
            "One day, a storm came raging through\n",
            "The winds were strong, the skies turned dark hue\n",
            "The ducks held on, with all their might\n",
            "But the little ones got lost, out of sight\n",
            "\n",
            "The mother duck searched, with a heavy heart\n",
            "She called out their names, but they were apart\n",
            "Tears rolled down her feathered cheeks\n",
            "As she feared the worst, in the midst of the freaks\n",
            "\n",
            "Days went by, and still no sign\n",
            "The pond felt empty, without the little ones' whine\n",
            "The mother duck couldn't take it anymore\n",
            "Her heart was broken, to the very core\n",
            "\n",
            "The father duck tried, to cheer her up\n",
            "But the sadness was too much, like a never-ending cup\n",
            "The pond that was once filled with joy and laughter\n",
            "Now echoed with the mother's mournful quackter\n",
            "\n",
            "The other ducks gathered, to pay their respects\n",
            "As they mourned the loss, of the little ducks' perfects\n",
            "The pond would never be the same\n",
            "For the ducks, it\n"
          ]
        }
      ],
      "source": [
        "print(llm(prompt.format(adjective='sad', subject='ducks')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0T8fpEz50g9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhEOwpHJ500S"
      },
      "source": [
        "\n",
        "The prompt template may contain:\n",
        "\n",
        "- instructions to the language model,\n",
        "\n",
        "- a set of few shot examples to help the language model generate a better response,\n",
        "\n",
        "- a question to the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0BqtqYIXbGgw"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "I want you to act as a naming consultant for new companies.\n",
        "\n",
        "Here are some examples of good company names:\n",
        "\n",
        "- search engine, Google\n",
        "- social media, Facebook\n",
        "- video sharing, YouTube\n",
        "\n",
        "The name should be short, catchy and easy to remember.\n",
        "\n",
        "What is a good name for a company that makes {product}?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt = prompt.format(product='news articles')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "97TlSlnKdChR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nSome suggestions could be:\\n\\n1. NewsWire\\n2. Headlines Inc.\\n3. PressPlay\\n4. BuzzFeed\\n5. InkSpot News\\n6. FreshPress Co.\\n7. NewsFlash Co.\\n8. The Daily Post\\n9. NewsNexus\\n10. ArticleSphere\\n\\nRemember to also consider incorporating relevant keywords or concepts into the name, such as \"news\" or \"articles\", to help convey the nature of the company\\'s business.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uQd_PUVdTEY"
      },
      "source": [
        "## Chains\n",
        "\n",
        "Using an LLM in isolation is fine for some simple applications, but many more complex ones require chaining LLMs - either with each other or with other experts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F1huuKOxdEYu"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ok-ZlxKBeD-A"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-zSswWbCeJZu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n\\nRainbow Socks Co. \\n'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"color full socks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-koI5cMepx4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_V-aFuzeoZT"
      },
      "source": [
        "## Agents & Tools\n",
        "\n",
        "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "\n",
        "- LLM: The language model powering the agent.\n",
        "\n",
        "- Agents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "##### ***Potential use cases:***\n",
        "- Personal Assistant\n",
        "- Question Answering\n",
        "- Chatbots\n",
        "- Code Understanding etc.\n",
        "\n",
        "\n",
        "Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
        "\n",
        "Agents: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dvMdC7IPeNZN"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q9YB2ud8hXmd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from wikipedia) (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D7FX-2CphYI5"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.7)\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tFEygEMGhmTL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lbjtmRPYh2ZK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m The first question is asking for a historical fact, while the second question is asking for a mathematical calculation. I should use both the wikipedia and Calculator tools.\n",
            "Action: wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one of the greatest players of all time, Messi has won a record eight Ballon d'Or awards, a record six European Golden Shoes, and was named the world's best player for a record eight times by FIFA. Until leaving the club in 2021, he had spent his entire professional career with Barcelona, where he won a club-record 34 trophies, including ten La Liga titles, seven Copa del Rey titles, and the UEFA Champions League four times. With his country, he won the 2021 Copa América and the 2022 FIFA World Cup. A prolific goalscorer and creative playmaker, Messi holds the records for most goals in La Liga (474), most hat-tricks in La Liga (36) and the UEFA Champions League (eight), and most assists in La Liga (192) and the Copa América (17). He also has the most international goals by a South American male (106). Messi has scored over 800 senior career goals for club and country, and has the most goals by a player for a single club (672).\n",
            "Messi relocated to Spain from Argentina aged 13 to join Barcelona, for whom he made his competitive debut aged 17 in October 2004. He established himself as an integral player for the club within the next three years, and in his first uninterrupted season in 2008–09 he helped Barcelona achieve the first treble in Spanish football; that year, aged 22, Messi won his first Ballon d'Or. Three successful seasons followed, with Messi winning four consecutive Ballons d'Or, making him the first player to win the award four times. During the 2011–12 season, he set the La Liga and European records for most goals scored in a single season, while establishing himself as Barcelona's all-time top scorer. The following two seasons, Messi finished second for the Ballon d'Or behind Cristiano Ronaldo (his perceived career rival), before regaining his best form during the 2014–15 campaign, becoming the all-time top scorer in La Liga and leading Barcelona to a historic second treble, after which he was awarded a fifth Ballon d'Or in 2015. Messi assumed captaincy of Barcelona in 2018, and won a record sixth Ballon d'Or in 2019. Out of contract, he signed for French club Paris Saint-Germain in August 2021, spending two seasons at the club and winning Ligue 1 twice. Messi joined American club Inter Miami in July 2023, winning the Leagues Cup in August of that year.\n",
            "An Argentine international, Messi is the country's all-time leading goalscorer and also holds the national record for appearances. At youth level, he won the 2005 FIFA World Youth Championship, finishing the tournament with both the Golden Ball and Golden Shoe, and an Olympic gold medal at the 2008 Summer Olympics. His style of play as a diminutive, left-footed dribbler drew comparisons with his compatriot Diego Maradona, who described Messi as his successor. After his senior debut in August 2005, Messi became the youngest Argentine to play and score in a FIFA World Cup (2006), and reached the final of the 2007 Copa América, where he was named young player of the tournament. As the squad's captain from August 2011, he led Argentina to three consecutive finals: the 2014 FIFA World Cup, for which he won the Golden Ball, the 2015 Copa América, winning the Golden Ball, and the 2016 Copa América. After announcing his international retirement in 2016, he reversed his decision and led his country to qualification for the 2018 FIFA World Cup, a third-place finish at the 2019 Copa América, and victory in the 2021 Copa América, while winning the Golden Ball and Golden Boot for the latter. That same year, Messi received a seventh Ballon d'Or. In 2022, he led Argentina to win the 2022 FIFA World Cup, where he won a record second Golden Ball, scored seven goals including two in the final\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now have the information I need to answer the first question. I should now use the Calculator tool to calculate Messi's current age raised to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 34^0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.555498776452875\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now have the answer to both questions.\n",
            "Final Answer: Lionel Messi joined Barcelona in 2004 and his current age raised to the 0.43 power is 4.555498776452875.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Lionel Messi joined Barcelona in 2004 and his current age raised to the 0.43 power is 4.555498776452875.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"What year did Lionel Messi Joined Barcelona? What is his current age raised to the 0.43 power?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNQoX_0jh3WS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgv7MHmVj7tb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEakMO40j8X2"
      },
      "source": [
        "### Memory\n",
        "\n",
        "\n",
        "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6DBXelFWj9xE"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "EJ7srgVMlNUd",
        "outputId": "44c641fc-576c-461c-ba98-c9fae9df8b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation = ConversationChain(llm=llm, verbose=True)\n",
        "\n",
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "UMoDdWEZlU14",
        "outputId": "99e3d986-5142-4188-f5b2-9c614be4cb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\n",
            "Human: Lets talk about how physics work on the Moon?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" Sure! The physics on the Moon are quite different from those on Earth due to its lower gravity and lack of atmosphere. Objects on the Moon will fall at a slower rate than on Earth, and the lack of air resistance means that there is no terminal velocity. The Moon's gravity is about one-sixth of Earth's, so objects will weigh less and have less inertia. Additionally, the Moon's surface is covered in fine dust called regolith, which can cause issues for astronauts and their equipment. Is there anything specific you would like to know about the physics on the Moon?\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input='Lets talk about how physics work on the Moon?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "x8wwQrlJlnK-",
        "outputId": "a042dd54-1cbb-44d1-c53a-9b015f8951ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hello! It's nice to meet you. I am an AI created by OpenAI. I am constantly learning and improving my abilities through machine learning algorithms. How can I assist you today?\n",
            "Human: Lets talk about how physics work on the Moon?\n",
            "AI:  Sure! The physics on the Moon are quite different from those on Earth due to its lower gravity and lack of atmosphere. Objects on the Moon will fall at a slower rate than on Earth, and the lack of air resistance means that there is no terminal velocity. The Moon's gravity is about one-sixth of Earth's, so objects will weigh less and have less inertia. Additionally, the Moon's surface is covered in fine dust called regolith, which can cause issues for astronauts and their equipment. Is there anything specific you would like to know about the physics on the Moon?\n",
            "Human: Why the gravitational field is lower?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" The gravitational field on the Moon is lower because it has less mass than Earth. The Moon's mass is about 1/81 of Earth's, which means it has less gravitational pull. This is also why objects weigh less on the Moon compared to Earth. Additionally, the Moon's smaller size means it has a weaker gravitational field.\""
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input='Why the gravitational field is lower?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dMwFUjnl0IN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGYGNFt6nNdX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpjGGoTDnNqB"
      },
      "source": [
        "### Document Loaders\n",
        "\n",
        "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into “documents” - a fancy way of say some pieces of text.\n",
        "\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "   ---------------------------------------- 0.0/286.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/286.1 kB ? eta -:--:--\n",
            "   - -------------------------------------- 10.2/286.1 kB ? eta -:--:--\n",
            "   ----------- --------------------------- 81.9/286.1 kB 919.0 kB/s eta 0:00:01\n",
            "   -------------------- ------------------- 143.4/286.1 kB 1.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 276.5/286.1 kB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 286.1/286.1 kB 1.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bb5iXF3GnPf1"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./Example_doc.pdf\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loK_z8d6nzYO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi9XXCm9oVao"
      },
      "source": [
        "### Indexes\n",
        "\n",
        "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains.\n",
        "\n",
        "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
        "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
        "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pT-q6SVboW0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests) (2022.12.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9T1xpYVfpJy5"
      },
      "outputs": [],
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader('./example_doc.txt')\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mLgw8m8gpN1L"
      },
      "outputs": [],
      "source": [
        "# documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DGmkltj-pPSV"
      },
      "outputs": [],
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJp4haDFpfIr",
        "outputId": "725e9a6e-0fe0-418c-86ba-9b81a81a0ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sbGHAnRgpg8F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (2.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (2.2.0+cu118)\n",
            "Requirement already satisfied: numpy in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (1.26.3)\n",
            "Requirement already satisfied: scikit-learn in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: scipy in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (1.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (0.21.3)\n",
            "Requirement already satisfied: Pillow in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sentence_transformers) (10.2.0)\n",
            "Requirement already satisfied: filelock in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\n",
            "Requirement already satisfied: requests in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: colorama in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XinCj71BprZb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "d:\\Guild\\TDL_TA\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\theun\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "# Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh8gvtrgsSr4",
        "outputId": "aece0485-44b3-47ac-b886-9d8de7e38bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy in d:\\guild\\tdl_ta\\.conda\\lib\\site-packages (from faiss-cpu) (1.26.3)\n",
            "Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
            "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/14.5 MB 2.4 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.7/14.5 MB 7.1 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 0.8/14.5 MB 6.0 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 1.0/14.5 MB 5.4 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 1.1/14.5 MB 5.1 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 1.1/14.5 MB 5.1 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 1.1/14.5 MB 3.4 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 1.8/14.5 MB 4.6 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 1.9/14.5 MB 4.5 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 2.1/14.5 MB 4.5 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 2.3/14.5 MB 4.4 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 2.5/14.5 MB 4.4 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 2.6/14.5 MB 4.3 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 2.8/14.5 MB 4.3 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 3.0/14.5 MB 4.3 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 3.2/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 3.4/14.5 MB 4.3 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 3.5/14.5 MB 4.3 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 3.7/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 3.9/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 4.1/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 4.3/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 4.4/14.5 MB 4.2 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 4.6/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 4.8/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 5.0/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 5.2/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 5.3/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 5.3/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 5.3/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 5.6/14.5 MB 3.9 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 6.0/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 6.2/14.5 MB 4.1 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 6.4/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 6.6/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 6.8/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 6.9/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 7.1/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 7.3/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 7.5/14.5 MB 4.1 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 7.7/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 7.8/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 8.0/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 8.2/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 8.4/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 8.6/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 8.7/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 8.9/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 9.1/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 9.3/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 9.5/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 9.6/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 9.8/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 10.0/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 10.2/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 10.3/14.5 MB 4.0 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 10.5/14.5 MB 4.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 10.7/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 10.9/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 11.1/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 11.3/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 11.4/14.5 MB 4.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 11.6/14.5 MB 4.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 11.8/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 12.0/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 12.2/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 12.3/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 12.5/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 12.7/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 12.9/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.1/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.2/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.4/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 13.6/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 13.8/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 13.9/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 14.1/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.3/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.5/14.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.5/14.5 MB 3.8 MB/s eta 0:00:00\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oSIbhjf2sWBY"
      },
      "outputs": [],
      "source": [
        "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "query = \"What did the president say about the Supreme Court\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYtXt7R5sYKQ",
        "outputId": "ec9c7866-3289-439e-ef9a-4a4bed44bc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chapter 1 The Fence\n",
            "Tom Sawyer lived with his aunt because his mother and\n",
            "father were dead. Tom didn’t like going to school, and he\n",
            "didn’t like working. He liked playing and having\n",
            "adventures. One Friday, he didn’t go to school—he went\n",
            "to the river.\n",
            "Aunt Polly was angry. “You’re a bad boy!” she said.\n",
            "“Tomorrow you can’t play with your friends because you\n",
            "didn’t go to school today. Tomorrow you’re going to work\n",
            "for me. You can paint the fence.”\n",
            "Saturday morning, Tom was not happy, but he started to\n",
            "paint the fence. His friend Jim was in the street.\n",
            "Tom asked him, “Do you want to paint?”\n",
            "Jim said, “No, I can’t. I’m going to get water.”\n",
            "Then Ben came to Tom’s house. He watched Tom and\n",
            "said, “I’m going to swim today. You can’t swim because\n",
            "you’re working.”\n",
            "Tom said, “This isn’t work. I like painting.”\n",
            "“Can I paint, too?” Ben asked.\n",
            "“No, you can’t,” Tom answered. “Aunt Polly asked me\n",
            "because I’m a very good painter.”\n",
            "Ben said, “I’m a good painter, too. Please, can I paint? I\n",
            "have some fruit. Do you want it?”\n",
            "OK,” Tom said. “Give me the fruit. Then you can paint.”\n",
            "Ben started to paint the fence. Later, many boys came to\n",
            "Tom’s house. They watched Ben, and they wanted to\n",
            "paint, too.\n",
            "Tom said, “Give me some food and you can paint.” \n",
            "Tom stayed in the yard, and the boys painted. They\n",
            "painted the fence three times. It was beautiful and white.\n",
            "Tom went into the house. “Aunt Polly, can I play now?”\n",
            "he asked.\n",
            "Aunt Polly was surprised. “Did you paint the fence?”\n",
            "she asked.\n",
            "“Yes, I did,” Tom answered.\n",
            "Aunt Polly went to the yard and looked at the fence. She\n",
            "was very surprised and very happy. “It’s beautiful!” she\n",
            "said. “Yes, you can play now.”\n",
            "Tom walked to his friend Joe Harper’s house and played\n",
            "with his friends there. Then he walked home again. There\n",
            "was a new girl in one yard. She had yellow hair and blue\n",
            "eyes. She was beautiful. Tom wanted to talk to her, but she\n",
            "didn’t see him. She went into her house. Tom waited, but\n",
            "she didn’t come out again.\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TsUGOu2Vs18A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Congrats!! You have learnt the Fundamentals of Langchain & LLms\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(\"Congrats!! You have learnt the Fundamentals of Langchain & LLms\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
